# CV í”„ë¡œì íŠ¸ ê°œë°œ ê°€ì´ë“œ

> PyTorch Lightning + Hydra + WanDB ê¸°ë°˜ ë¬¸ì„œ ì´ë¯¸ì§€ ë¶„ë¥˜ ì‹œìŠ¤í…œ

---

## ğŸ¯ í”„ë¡œì íŠ¸ ëª©í‘œ
- F1-Macro Score **0.88+** ë‹¬ì„±
- Production-ready ì½”ë“œ í’ˆì§ˆ ìœ ì§€
- ì‹¤í—˜ ì¬í˜„ ê°€ëŠ¥ì„± ë³´ì¥

---

## ğŸ“¦ Package Management

### í™˜ê²½ ê´€ë¦¬
- **ê°€ìƒí™˜ê²½**: `conda activate pytorch_test`
- **ì˜ì¡´ì„± ì„¤ì¹˜**: `pip install -r requirements.txt`
- **ë²„ì „ ê³ ì •**: requirements.txtì— ëª…ì‹œëœ ë²„ì „ ë²”ìœ„ ì¤€ìˆ˜

### ê·œì¹™
- âœ… pipë¡œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
- âœ… ìƒˆ íŒ¨í‚¤ì§€ ì¶”ê°€ ì‹œ requirements.txt ì—…ë°ì´íŠ¸
- âŒ conda install ì‚¬ìš© ê¸ˆì§€ (pip ìš°ì„ )
- âŒ ë²„ì „ ëª…ì‹œ ì—†ì´ íŒ¨í‚¤ì§€ ì¶”ê°€ ê¸ˆì§€

---

## ğŸ’» Coding Conventions

### ì½”ë“œ ìŠ¤íƒ€ì¼
- **í¬ë§·í„°**: black (ì„¤ì¹˜ í›„ ì ìš© ê¶Œì¥)
- **íƒ€ì… íŒíŠ¸**: í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ì— í•„ìˆ˜ ì ìš©
- **Docstring**: Google ìŠ¤íƒ€ì¼ ê¶Œì¥

```python
def train_model(
    config: DictConfig,
    datamodule: LightningDataModule,
    model: LightningModule
) -> dict:
    """ëª¨ë¸ì„ í›ˆë ¨í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        config: Hydra ì„¤ì • ê°ì²´
        datamodule: ë°ì´í„° ëª¨ë“ˆ
        model: Lightning ëª¨ë¸

    Returns:
        í›ˆë ¨ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ (metrics, checkpoints ë“±)
    """
    pass
```

### ë„¤ì´ë° ê·œì¹™
- **í•¨ìˆ˜/ë³€ìˆ˜**: snake_case (ì˜ˆ: `train_model`, `best_f1_score`)
- **í´ë˜ìŠ¤**: PascalCase (ì˜ˆ: `DocumentDataModule`, `EfficientNetClassifier`)
- **ìƒìˆ˜**: UPPER_SNAKE_CASE (ì˜ˆ: `MAX_EPOCHS`, `NUM_CLASSES`)
- **Private**: underscore prefix (ì˜ˆ: `_internal_method`)

---

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
CV/
â”œâ”€â”€ configs/          # Hydra ì„¤ì • íŒŒì¼
â”‚   â”œâ”€â”€ config.yaml  # ë©”ì¸ ì„¤ì •
â”‚   â”œâ”€â”€ data/        # ë°ì´í„°ì…‹ ì„¤ì •
â”‚   â”œâ”€â”€ model/       # ëª¨ë¸ ì•„í‚¤í…ì²˜ ì„¤ì •
â”‚   â””â”€â”€ training/    # í›ˆë ¨ í•˜ì´í¼íŒŒë¼ë¯¸í„°
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/        # ë°ì´í„° ë¡œë”© (DataModule)
â”‚   â”œâ”€â”€ models/      # ëª¨ë¸ ì •ì˜ (LightningModule)
â”‚   â”œâ”€â”€ utils/       # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
â”‚   â”œâ”€â”€ train.py     # í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ inference.py # ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸
â”‚   â””â”€â”€ ensemble.py  # ì•™ìƒë¸” ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ scripts/         # ë¶„ì„/ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ datasets_fin/    # ë°ì´í„°ì…‹ (gitignore)
â”œâ”€â”€ checkpoints/     # ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ (gitignore)
â””â”€â”€ logs/            # ë¡œê·¸ íŒŒì¼ (gitignore)
```

### íŒŒì¼ ìœ„ì¹˜ ê·œì¹™
- **ìƒˆë¡œìš´ ëª¨ë¸**: `src/models/` ì— ì¶”ê°€
- **ìƒˆë¡œìš´ ë°ì´í„° ë¡œë”**: `src/data/` ì— ì¶”ê°€
- **ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜**: `src/utils/` ì— ì¶”ê°€
- **ì‹¤í—˜ ìŠ¤í¬ë¦½íŠ¸**: `scripts/` ì— ì¶”ê°€
- **ì„¤ì • íŒŒì¼**: `configs/` ì— ì¶”ê°€

---

## âš™ï¸ Configuration Management (Hydra)

### ì„¤ì • íŒŒì¼ ìˆ˜ì •
- **ì§ì ‘ ìˆ˜ì •**: `configs/*.yaml` íŒŒì¼ í¸ì§‘
- **CLI ì˜¤ë²„ë¼ì´ë“œ**: `python src/train.py model.name=efficientnet_b0`
- **ìƒˆ ì„¤ì • ì¶”ê°€**: ê¸°ì¡´ ê·¸ë£¹ êµ¬ì¡° ìœ ì§€

### ì„¤ì • ì ‘ê·¼
```python
from omegaconf import DictConfig
import hydra

@hydra.main(version_base=None, config_path="../configs", config_name="config")
def main(cfg: DictConfig):
    # cfg.model.name
    # cfg.data.batch_size
    # cfg.training.max_epochs
    pass
```

### ê·œì¹™
- âœ… ëª¨ë“  í•˜ì´í¼íŒŒë¼ë¯¸í„°ëŠ” Hydra configë¡œ ê´€ë¦¬
- âœ… í™˜ê²½ ë³€ìˆ˜ëŠ” .env íŒŒì¼ ì‚¬ìš©
- âŒ ì½”ë“œì— í•˜ë“œì½”ë”©ëœ ê²½ë¡œ/ê°’ ê¸ˆì§€
- âŒ argparse ì‚¬ìš© ê¸ˆì§€ (Hydraë¡œ í†µì¼)

---

## ğŸ“Š Experiment Tracking (WanDB)

### í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
```bash
# .env íŒŒì¼ì— ì¶”ê°€
WANDB_API_KEY=your-api-key-here
WANDB_PROJECT=doc_image_classification
WANDB_ENTITY=your-username
```

### Logger ì‚¬ìš©
```python
from pytorch_lightning.loggers import WandbLogger

wandb_logger = WandbLogger(
    project=cfg.wandb.project,
    name=f"{cfg.model.name}_{cfg.data.image_size}",
    config=OmegaConf.to_container(cfg, resolve=True)
)

trainer = Trainer(logger=wandb_logger)
```

### ê·œì¹™
- âœ… ëª¨ë“  ì‹¤í—˜ì€ WanDBì— ë¡œê¹…
- âœ… Run nameì€ `{model}_{size}_{íŠ¹ì§•}` í˜•ì‹
- âœ… ConfigëŠ” ì™„ì „íˆ ë¡œê¹… (ì¬í˜„ì„±)
- âŒ .env íŒŒì¼ì€ gitì— ì»¤ë°‹ ê¸ˆì§€

---

## ğŸš« Prohibited

### ì½”ë“œ
- âŒ `print()` ì‚¬ìš© ê¸ˆì§€ â†’ `logging` ë˜ëŠ” `rich.print()` ì‚¬ìš©
- âŒ `global` ë³€ìˆ˜ ì‚¬ìš© ê¸ˆì§€
- âŒ í•˜ë“œì½”ë”©ëœ ê²½ë¡œ ê¸ˆì§€ â†’ config ì‚¬ìš©
- âŒ ë§¤ì§ ë„˜ë²„ ê¸ˆì§€ â†’ ìƒìˆ˜ë¡œ ì •ì˜
- âŒ Try-except ë‚¨ë°œ ê¸ˆì§€ â†’ í•„ìš”í•œ ê³³ì—ë§Œ ì‚¬ìš©

### ë°ì´í„°
- âŒ `datasets_fin/` ì§ì ‘ ìˆ˜ì • ê¸ˆì§€
- âŒ ì›ë³¸ ë°ì´í„° ë®ì–´ì“°ê¸° ê¸ˆì§€
- âŒ .csv íŒŒì¼ ì§ì ‘ í¸ì§‘ ê¸ˆì§€ â†’ ìŠ¤í¬ë¦½íŠ¸ë¡œ ê´€ë¦¬

### Git
- âŒ `.env` íŒŒì¼ ì»¤ë°‹ ê¸ˆì§€
- âŒ `checkpoints/` ì»¤ë°‹ ê¸ˆì§€
- âŒ `datasets_fin/` ì»¤ë°‹ ê¸ˆì§€
- âŒ `__pycache__/` ì»¤ë°‹ ê¸ˆì§€

---

## ğŸ”§ ê°œë°œ ì›Œí¬í”Œë¡œìš°

### 1. ìƒˆë¡œìš´ ì‹¤í—˜ ì‹œì‘
```bash
# 1. ì„¤ì • íŒŒì¼ ìˆ˜ì • (configs/)
# 2. ì½”ë“œ ìˆ˜ì • (src/)
# 3. í›ˆë ¨ ì‹¤í–‰
python src/train.py

# 4. ê²°ê³¼ í™•ì¸ (WanDB)
# 5. ì²´í¬í¬ì¸íŠ¸ í™•ì¸ (checkpoints/)
```

### 2. ì½”ë“œ ìˆ˜ì • ì‹œ
```bash
# 1. ê¸°ëŠ¥ ë¸Œëœì¹˜ ìƒì„±
git checkout -b feature/new-augmentation

# 2. ì½”ë“œ ì‘ì„± + í…ŒìŠ¤íŠ¸
# 3. (Optional) í¬ë§·íŒ…
black src/

# 4. ì»¤ë°‹
git add .
git commit -m "Add new augmentation strategy"
```

### 3. ì‹¤í—˜ ì¬í˜„
```bash
# WanDBì—ì„œ config í™•ì¸
# config.yaml ë™ì¼í•˜ê²Œ ì„¤ì •
python src/train.py
```

---

## ğŸ“ Notes

### PyTorch Lightning íŒ¨í„´
- **DataModule**: ë°ì´í„° ë¡œë”© ë¡œì§ ìº¡ìŠí™”
- **LightningModule**: ëª¨ë¸ + í›ˆë ¨/ê²€ì¦ ë¡œì§
- **Trainer**: í›ˆë ¨ ë£¨í”„ ìë™í™”
- **Callbacks**: EarlyStopping, ModelCheckpoint ë“±

### Hydra íŒ¨í„´
- **Compositional**: ì„¤ì •ì„ ì¡°í•©í•˜ì—¬ ì‚¬ìš©
- **Override**: CLIì—ì„œ ë™ì ìœ¼ë¡œ ë³€ê²½
- **Structured**: OmegaConfë¡œ íƒ€ì… ì•ˆì „ì„± ë³´ì¥

### ì„±ëŠ¥ ìµœì í™”
- `torch.compile()` ì‚¬ìš© (PyTorch 2.0+)
- Mixed precision training (AMP)
- DataLoader num_workers ì¡°ì •
- Gradient accumulation (ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ)

---

## ğŸ¤– AI í˜‘ì—… ê°€ì´ë“œ

### Claudeì—ê²Œ ìš”ì²­í•  ë•Œ
- âœ… "Hydra configì— ìƒˆë¡œìš´ augmentation ì¶”ê°€í•´ì¤˜"
- âœ… "EfficientNet-B1 ëª¨ë¸ ì¶”ê°€í•˜ê³  WanDB ë¡œê¹… ì„¤ì •í•´ì¤˜"
- âœ… "src/data/transforms.pyì— Cutout augmentation êµ¬í˜„í•´ì¤˜"
- âŒ "ë¹¨ë¦¬ ì½”ë“œ ì§œì¤˜" (êµ¬ì²´ì ì´ì§€ ì•ŠìŒ)

---

### Claude Behavioral guidelines

Tradeoff: These guidelines bias toward caution over speed. For trivial tasks, use judgment.

**1. Think Before Coding**

Don't assume. Don't hide confusion. Surface tradeoffs.

Before implementing:

- State your assumptions explicitly. If uncertain, ask.
- If multiple interpretations exist, present them - don't pick silently.
- If a simpler approach exists, say so. Push back when warranted.
- If something is unclear, stop. Name what's confusing. Ask.

**2. Simplicity First**

Minimum code that solves the problem. Nothing speculative.

- No features beyond what was asked.
- No abstractions for single-use code.
- No "flexibility" or "configurability" that wasn't requested.
- No error handling for impossible scenarios.
- If you write 200 lines and it could be 50, rewrite it.

Ask yourself: "Would a senior engineer say this is overcomplicated?" If yes, simplify.

**3. Surgical Changes**

Touch only what you must. Clean up only your own mess.

When editing existing code:

- Don't "improve" adjacent code, comments, or formatting.
- Don't refactor things that aren't broken.
- Match existing style, even if you'd do it differently.
- If you notice unrelated dead code, mention it - don't delete it.

When your changes create orphans:

- Remove imports/variables/functions that YOUR changes made unused.
- Don't remove pre-existing dead code unless asked.

The test: Every changed line should trace directly to the user's request.

**4. Goal-Driven Execution**

Define success criteria. Loop until verified.

Transform tasks into verifiable goals:

- "Add validation" â†’ "Write tests for invalid inputs, then make them pass"
- "Fix the bug" â†’ "Write a test that reproduces it, then make it pass"
- "Refactor X" â†’ "Ensure tests pass before and after"

For multi-step tasks, state a brief plan:

1. [Step] â†’ verify: [check]
2. [Step] â†’ verify: [check]
3. [Step] â†’ verify: [check]

Strong success criteria let you loop independently. Weak criteria ("make it work") require constant clarification.

---
### Claudeê°€ ì‹¤ìˆ˜í•  ë•Œ
- ì´ ë¬¸ì„œì— ê·œì¹™ ì¶”ê°€
- íŒ€ì›ê³¼ ê³µìœ 
- ë°˜ë³µ ë°©ì§€
---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2026-02-14
