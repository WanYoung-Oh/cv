"""
ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
"""

import os
import json
import logging
from pathlib import Path
from typing import Dict, Any, Optional, List, TYPE_CHECKING

import pandas as pd
import numpy as np

if TYPE_CHECKING:
    from omegaconf import DictConfig
    from src.data.datamodule import DocumentImageDataModule

log = logging.getLogger(__name__)


def save_json(data: Dict[str, Any], save_path: str) -> None:
    """ë°ì´í„°ë¥¼ JSONìœ¼ë¡œ ì €ì¥"""
    save_path = Path(save_path)
    save_path.parent.mkdir(parents=True, exist_ok=True)

    with open(save_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=2, ensure_ascii=False)


def load_json(path: str) -> Dict[str, Any]:
    """JSON íŒŒì¼ ë¡œë“œ"""
    with open(path, 'r', encoding='utf-8') as f:
        return json.load(f)


def extract_val_f1_from_filename(checkpoint_path: Path) -> Optional[float]:
    """
    ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ëª…ì—ì„œ val_f1 ë©”íŠ¸ë¦­ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.

    Args:
        checkpoint_path: ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ê²½ë¡œ (ì˜ˆ: epoch=10-val_f1=0.950.ckpt)

    Returns:
        ì¶”ì¶œëœ val_f1 ê°’, ì‹¤íŒ¨ ì‹œ None

    Example:
        >>> extract_val_f1_from_filename(Path("epoch=10-val_f1=0.950.ckpt"))
        0.950
    """
    try:
        filename = checkpoint_path.stem
        if 'val_f1=' in filename:
            val_f1_str = filename.split('val_f1=')[1]
            return float(val_f1_str)
    except (ValueError, IndexError):
        pass
    return None


def create_datamodule_from_config(cfg: "DictConfig") -> "DocumentImageDataModule":
    """
    Hydra configì—ì„œ DocumentImageDataModuleì„ ìƒì„±í•©ë‹ˆë‹¤.

    ì´ í•¨ìˆ˜ëŠ” ensemble.pyì™€ inference.pyì—ì„œ ì¤‘ë³µëœ DataModule ìƒì„± ë¡œì§ì„
    ë‹¨ì¼ íŒ©í† ë¦¬ í•¨ìˆ˜ë¡œ í†µí•©í•©ë‹ˆë‹¤.

    Args:
        cfg: Hydra ì„¤ì • ê°ì²´ (cfg.data, cfg.training í¬í•¨)

    Returns:
        ì„¤ì •ëœ DocumentImageDataModule ì¸ìŠ¤í„´ìŠ¤

    Example:
        >>> data_module = create_datamodule_from_config(cfg)
        >>> data_module.setup()
        >>> test_loader = data_module.test_dataloader()
    """
    from src.data.datamodule import DocumentImageDataModule

    return DocumentImageDataModule(
        data_root=cfg.data.root_path,
        train_csv=cfg.data.train_csv,
        test_csv=cfg.data.test_csv,
        train_image_dir=cfg.data.get('train_image_dir', 'train/'),
        test_image_dir=cfg.data.get('test_image_dir', 'test/'),
        img_size=cfg.data.img_size,
        batch_size=cfg.training.batch_size,
        num_workers=cfg.training.num_workers,
        train_val_split=cfg.data.train_val_split,
        normalization=cfg.data.normalization,
        augmentation=cfg.data.augmentation,
        drop_last=cfg.training.get('drop_last', False),
    )


def save_predictions_to_csv(
    predictions: List[int],
    output_path: str,
    data_root: str,
    test_csv_path: Optional[str] = None,
    task_name: str = "Inference"
) -> pd.DataFrame:
    """
    ì˜ˆì¸¡ ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥í•˜ê³  í´ë˜ìŠ¤ ë¶„í¬ë¥¼ ë¡œê¹…í•©ë‹ˆë‹¤.

    ì´ í•¨ìˆ˜ëŠ” ensemble.pyì™€ inference.pyì—ì„œ ì¤‘ë³µëœ ê²°ê³¼ ì €ì¥ ë¡œì§ì„
    ë‹¨ì¼ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë¡œ í†µí•©í•©ë‹ˆë‹¤.

    Args:
        predictions: ì˜ˆì¸¡ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        output_path: ì €ì¥í•  CSV íŒŒì¼ ê²½ë¡œ
        data_root: ë°ì´í„° ë£¨íŠ¸ ê²½ë¡œ
        test_csv_path: í…ŒìŠ¤íŠ¸ CSV ê²½ë¡œ (optional)
        task_name: ì‘ì—… ì´ë¦„ (ë¡œê¹…ìš©, default: "Inference")

    Returns:
        ì €ì¥ëœ DataFrame

    Example:
        >>> predictions = [0, 1, 2, 0, 1]
        >>> df = save_predictions_to_csv(
        ...     predictions=predictions,
        ...     output_path="results/pred.csv",
        ...     data_root="datasets_fin/",
        ...     task_name="Ensemble"
        ... )
    """
    # sample_submission.csvê°€ ìˆìœ¼ë©´ ê·¸ í˜•ì‹ ë”°ë¥´ê¸°
    sample_submission_path = os.path.join(data_root, "sample_submission.csv")

    if os.path.exists(sample_submission_path):
        log.info(f"sample_submission.csv í˜•ì‹ ì‚¬ìš©: {sample_submission_path}")
        sample_df = pd.read_csv(sample_submission_path)
        sample_df.iloc[:, 1] = predictions[:len(sample_df)]
        result_df = sample_df
    else:
        # ê¸°ë³¸ í˜•ì‹ìœ¼ë¡œ ì €ì¥ (id, target)
        log.info("ê¸°ë³¸ í˜•ì‹ìœ¼ë¡œ ì €ì¥ (id, target)")
        if test_csv_path and os.path.exists(test_csv_path):
            test_df = pd.read_csv(test_csv_path)
            image_ids = test_df.iloc[:, 0].tolist()
        else:
            # test CSVê°€ ì—†ìœ¼ë©´ ì¸ë±ìŠ¤ ì‚¬ìš©
            image_ids = list(range(len(predictions)))

        result_df = pd.DataFrame({
            'id': image_ids[:len(predictions)],
            'target': predictions
        })

    # CSV ì €ì¥
    result_df.to_csv(output_path, index=False)

    # ì™„ë£Œ ë¡œê¹…
    log.info("=" * 70)
    log.info(f"âœ… {task_name} ì™„ë£Œ!")
    log.info(f"ğŸ“„ ê²°ê³¼ ì €ì¥: {output_path}")
    log.info("=" * 70)

    # í´ë˜ìŠ¤ë³„ ì˜ˆì¸¡ ë¶„í¬ ì¶œë ¥
    pred_counts = pd.Series(predictions).value_counts().sort_index()
    log.info(f"\nğŸ“ˆ ì˜ˆì¸¡ í´ë˜ìŠ¤ ë¶„í¬:")
    for class_id, count in pred_counts.items():
        log.info(f"  í´ë˜ìŠ¤ {class_id}: {count:4d} ({count/len(predictions)*100:5.2f}%)")

    return result_df
