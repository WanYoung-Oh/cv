"""
Inference ìŠ¤í¬ë¦½íŠ¸
í•™ìŠµëœ ëª¨ë¸ë¡œ test ë°ì´í„°ì…‹ì— ëŒ€í•œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ê³  pred.csv ìƒì„±
"""

import os
import sys
import logging
import json
from pathlib import Path
from typing import Optional, List

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€ (ì–´ë””ì„œë“  ì‹¤í–‰ ê°€ëŠ¥í•˜ë„ë¡)
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import torch
import pandas as pd
import hydra
from omegaconf import DictConfig
from tqdm import tqdm

from src.data.datamodule import DocumentImageDataModule
from src.models.module import DocumentClassifierModule
from src.utils.device import get_simple_device
from src.utils.helpers import (
    extract_val_f1_from_filename,
    create_datamodule_from_config,
    save_predictions_to_csv
)


log = logging.getLogger(__name__)


def get_champion_checkpoint(checkpoint_dir: Path) -> Optional[Path]:
    """ì±”í”¼ì–¸ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ì°¾ê¸°

    Args:
        checkpoint_dir: ì²´í¬í¬ì¸íŠ¸ ë² ì´ìŠ¤ ë””ë ‰í† ë¦¬

    Returns:
        ì±”í”¼ì–¸ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ë˜ëŠ” None
    """
    champion_dir = checkpoint_dir / "champion"
    champion_checkpoint = champion_dir / "best_model.ckpt"
    champion_info_path = champion_dir / "champion_info.json"

    if champion_checkpoint.exists():
        # ì±”í”¼ì–¸ ì •ë³´ ë¡œë“œ
        if champion_info_path.exists():
            with open(champion_info_path, 'r') as f:
                champion_info = json.load(f)

            log.info("ğŸ† ì±”í”¼ì–¸ ëª¨ë¸ ë¡œë“œ")
            log.info(f"   val_f1: {champion_info.get('val_f1', 'N/A')}")
            log.info(f"   ì›ë³¸ ê²½ë¡œ: {champion_info.get('checkpoint_path', 'N/A')}")
            log.info(f"   ì—…ë°ì´íŠ¸: {champion_info.get('updated_at', 'N/A')}")

        return champion_checkpoint

    return None


def find_checkpoint_by_run_id(checkpoint_dir: Path, run_id: str) -> Optional[Path]:
    """íŠ¹ì • run_idì˜ best checkpoint ì°¾ê¸°

    Args:
        checkpoint_dir: ì²´í¬í¬ì¸íŠ¸ ë² ì´ìŠ¤ ë””ë ‰í† ë¦¬
        run_id: ì‹¤í—˜ run ID (ì˜ˆ: 20260216_run_001)

    Returns:
        í•´ë‹¹ runì˜ best checkpoint ê²½ë¡œ ë˜ëŠ” None
    """
    run_dir = checkpoint_dir / run_id

    if not run_dir.exists():
        log.error(f"Run ID '{run_id}'ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {run_dir}")
        log.info("\nì‚¬ìš© ê°€ëŠ¥í•œ Run ID ëª©ë¡:")
        for exp_dir in checkpoint_dir.iterdir():
            if exp_dir.is_dir() and exp_dir.name != "champion":
                log.info(f"  - {exp_dir.name}")
        return None

    # experiment_info.jsonì—ì„œ best_checkpoint ì •ë³´ ì½ê¸°
    exp_info_path = run_dir / "experiment_info.json"
    if exp_info_path.exists():
        with open(exp_info_path, 'r') as f:
            exp_info = json.load(f)

        log.info(f"ğŸ“‹ Run ID '{run_id}' ì •ë³´:")
        log.info(f"   ëª¨ë¸: {exp_info.get('model_name', 'N/A')}")
        log.info(f"   ì‹œì‘: {exp_info.get('started_at', 'N/A')}")
        log.info(f"   val_f1: {exp_info.get('val_f1', 'N/A')}")

        best_ckpt_path = exp_info.get('best_checkpoint')
        if best_ckpt_path and Path(best_ckpt_path).exists():
            return Path(best_ckpt_path)

    # experiment_infoê°€ ì—†ê±°ë‚˜ best_checkpoint ì •ë³´ê°€ ì—†ìœ¼ë©´
    # íŒŒì¼ëª…ì—ì„œ ê°€ì¥ ë†’ì€ val_f1ì„ ê°€ì§„ checkpoint ì°¾ê¸°
    log.info("experiment_info.jsonì—ì„œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ëª…ì—ì„œ íƒìƒ‰ ì¤‘...")
    ckpt_files = list(run_dir.glob("*.ckpt"))
    best_checkpoint = None
    best_metric = 0.0

    for ckpt_file in ckpt_files:
        val_f1 = extract_val_f1_from_filename(ckpt_file)
        if val_f1 is not None and val_f1 > best_metric:
            best_metric = val_f1
            best_checkpoint = ckpt_file

    if best_checkpoint:
        log.info(f"ìµœê³  ì„±ëŠ¥ ì²´í¬í¬ì¸íŠ¸ ë°œê²¬: val_f1={best_metric:.4f}")

    return best_checkpoint


def find_best_checkpoint(checkpoint_dir: Path) -> Optional[Path]:
    """ëª¨ë“  ì‹¤í—˜ ì¤‘ ìµœê³  ì„±ëŠ¥ ì²´í¬í¬ì¸íŠ¸ ì°¾ê¸°

    Args:
        checkpoint_dir: ì²´í¬í¬ì¸íŠ¸ ë² ì´ìŠ¤ ë””ë ‰í† ë¦¬

    Returns:
        ìµœê³  ì„±ëŠ¥ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ë˜ëŠ” None
    """
    best_checkpoint = None
    best_metric = 0.0

    # ëª¨ë“  ì‹¤í—˜ ë””ë ‰í† ë¦¬ íƒìƒ‰
    for exp_dir in checkpoint_dir.iterdir():
        if not exp_dir.is_dir() or exp_dir.name == "champion":
            continue

        # í•´ë‹¹ ì‹¤í—˜ì˜ ì²´í¬í¬ì¸íŠ¸ ì°¾ê¸°
        ckpt_files = list(exp_dir.glob("*.ckpt"))

        for ckpt_file in ckpt_files:
            val_f1 = extract_val_f1_from_filename(ckpt_file)
            if val_f1 is not None and val_f1 > best_metric:
                best_metric = val_f1
                best_checkpoint = ckpt_file

    if best_checkpoint:
        log.info(f"ìµœê³  ì„±ëŠ¥ ì²´í¬í¬ì¸íŠ¸ ë°œê²¬: val_f1={best_metric:.4f}")
        log.info(f"ê²½ë¡œ: {best_checkpoint}")

    return best_checkpoint


def get_test_image_ids(test_csv_path: str) -> List[str]:
    """í…ŒìŠ¤íŠ¸ CSVì—ì„œ ì´ë¯¸ì§€ ID ì¶”ì¶œ

    Args:
        test_csv_path: í…ŒìŠ¤íŠ¸ CSV íŒŒì¼ ê²½ë¡œ

    Returns:
        ì´ë¯¸ì§€ ID ë¦¬ìŠ¤íŠ¸
    """
    df = pd.read_csv(test_csv_path)
    # ì²« ë²ˆì§¸ ì»¬ëŸ¼ì´ ì´ë¯¸ì§€ íŒŒì¼ëª… ë˜ëŠ” IDë¼ê³  ê°€ì •
    return df.iloc[:, 0].tolist()


@hydra.main(version_base=None, config_path="../configs", config_name="config")
def main(cfg: DictConfig) -> None:
    """ë©”ì¸ inference í•¨ìˆ˜

    Hydra configë¡œ inference ì„¤ì • ê´€ë¦¬:
        inference.checkpoint: ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ (ì„ íƒì‚¬í•­, ìµœìš°ì„ )
        inference.run_id: ì‹¤í—˜ run ID (ì„ íƒì‚¬í•­, 2ìˆœìœ„)
        inference.output: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: pred.csv)

    ì‚¬ìš© ì˜ˆì‹œ:
        # Champion ëª¨ë¸ ì‚¬ìš© (ê¸°ë³¸)
        python src/inference.py

        # íŠ¹ì • run_id ì‚¬ìš©
        python src/inference.py inference.run_id=20260216_run_001

        # ì§ì ‘ checkpoint ê²½ë¡œ ì§€ì •
        python src/inference.py inference.checkpoint=checkpoints/20260216_run_001/epoch=10-val_f1=0.950.ckpt
    """
    # Hydra configì—ì„œ inference ì„¤ì • ì½ê¸°
    inference_cfg = cfg.get('inference', {})
    checkpoint_path = inference_cfg.get('checkpoint', None)
    run_id = inference_cfg.get('run_id', None)

    # ì¶œë ¥ ê²½ë¡œ: datasets_fin/submission/submission_{model_name}.csv
    model_name = cfg.model.model_name
    submission_dir = os.path.join(cfg.data.root_path, "submission")
    default_output = os.path.join(submission_dir, f"submission_{model_name}.csv")
    output_path = inference_cfg.get('output', default_output)

    log.info("=" * 70)
    log.info("ğŸ”® Inference ì‹œì‘")
    log.info("=" * 70)

    # ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ì°¾ê¸°
    if not checkpoint_path:
        checkpoint_dir = Path(cfg.checkpoint_dir)

        if not checkpoint_dir.exists():
            raise FileNotFoundError(
                f"ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ '{checkpoint_dir}'ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
            )

        # 1ìˆœìœ„: run_id ì§€ì •
        if run_id:
            log.info(f"Run ID '{run_id}'ì˜ ëª¨ë¸ íƒìƒ‰ ì¤‘...")
            run_ckpt = find_checkpoint_by_run_id(checkpoint_dir, run_id)

            if run_ckpt:
                checkpoint_path = str(run_ckpt)
                log.info(f"âœ… Run ID '{run_id}' ëª¨ë¸ ì‚¬ìš©")
            else:
                raise FileNotFoundError(
                    f"Run ID '{run_id}'ì˜ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
                    f"'{checkpoint_dir}' ë””ë ‰í† ë¦¬ë¥¼ í™•ì¸í•˜ì„¸ìš”."
                )
        else:
            # 2ìˆœìœ„: ì±”í”¼ì–¸ ëª¨ë¸
            champion_ckpt = get_champion_checkpoint(checkpoint_dir)
            if champion_ckpt:
                checkpoint_path = str(champion_ckpt)
                log.info("âœ… ì±”í”¼ì–¸ ëª¨ë¸ ì‚¬ìš©")
            else:
                # 3ìˆœìœ„: ëª¨ë“  ì‹¤í—˜ ì¤‘ ìµœê³  ì„±ëŠ¥ ëª¨ë¸
                log.info("ì±”í”¼ì–¸ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ìµœê³  ì„±ëŠ¥ ëª¨ë¸ íƒìƒ‰ ì¤‘...")
                best_ckpt = find_best_checkpoint(checkpoint_dir)

                if best_ckpt:
                    checkpoint_path = str(best_ckpt)
                    log.info("âœ… ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì‚¬ìš©")
                else:
                    raise FileNotFoundError(
                        f"ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
                        f"'{checkpoint_dir}' ë””ë ‰í† ë¦¬ì— í•™ìŠµëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.\n"
                        f"ë¨¼ì € 'python src/train.py'ë¡œ ëª¨ë¸ì„ í•™ìŠµí•˜ì„¸ìš”."
                    )

    if not os.path.exists(checkpoint_path):
        raise FileNotFoundError(f"ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {checkpoint_path}")

    log.info(f"ì‚¬ìš© ì²´í¬í¬ì¸íŠ¸: {checkpoint_path}")

    # ë°ì´í„°ëª¨ë“ˆ ìƒì„±
    # inferenceëŠ” sample_submission.csvë¥¼ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì†ŒìŠ¤ë¡œ ì‚¬ìš©
    submission_csv = cfg.data.get('sample_submission_csv', cfg.data.get('test_csv', None))
    if not submission_csv:
        raise ValueError("cfg.data.sample_submission_csv ë˜ëŠ” cfg.data.test_csvê°€ í•„ìš”í•©ë‹ˆë‹¤.")

    submission_csv_path = os.path.join(cfg.data.root_path, submission_csv)
    if not os.path.exists(submission_csv_path):
        raise FileNotFoundError(
            f"Submission CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {submission_csv_path}\n"
            f"ë°ì´í„°ì…‹ì„ ë¨¼ì € ì¤€ë¹„í•´ì£¼ì„¸ìš”."
        )

    log.info(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° (submission): {submission_csv_path}")

    # DataModule ìƒì„± (íŒ©í† ë¦¬ í•¨ìˆ˜ ì‚¬ìš©, sample_submission_csvë¥¼ test_csvë¡œ ì „ë‹¬)
    data_module = create_datamodule_from_config(cfg)
    data_module.setup()

    # ëª¨ë¸ ë¡œë“œ
    log.info("ëª¨ë¸ ë¡œë“œ ì¤‘...")
    model = DocumentClassifierModule.load_from_checkpoint(checkpoint_path)
    model.eval()

    # ë””ë°”ì´ìŠ¤ ì„¤ì • (CUDA -> MPS -> CPU ìë™ ê°ì§€)
    device = get_simple_device()
    model = model.to(device)
    log.info(f"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")

    # Inference ìˆ˜í–‰
    log.info("Inference ìˆ˜í–‰ ì¤‘...")
    predictions = []

    test_loader = data_module.test_dataloader()

    with torch.no_grad():
        for batch in tqdm(test_loader, desc="Predicting"):
            images, _ = batch
            images = images.to(device)

            logits = model(images)
            preds = logits.argmax(dim=1)

            predictions.extend(preds.cpu().numpy().tolist())

    log.info(f"ì´ ì˜ˆì¸¡ ìˆ˜: {len(predictions)}")

    # ê²°ê³¼ ì €ì¥ (ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì‚¬ìš©)
    result_df = save_predictions_to_csv(
        predictions=predictions,
        output_path=output_path,
        data_root=cfg.data.root_path,
        test_csv_path=submission_csv_path,
        task_name="Inference",
    )

    # ì˜ˆì¸¡ ìƒ˜í”Œ ì¶œë ¥
    log.info(f"ğŸ“Š ì˜ˆì¸¡ ìƒ˜í”Œ:")
    log.info(f"\n{result_df.head(10)}")


if __name__ == "__main__":
    main()
