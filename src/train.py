"""
ë©”ì¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
Hydra + PyTorch Lightning + WanDB
"""

import logging
import os
import sys
import shutil
import json
from pathlib import Path
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€ (ì–´ë””ì„œë“  ì‹¤í–‰ ê°€ëŠ¥í•˜ë„ë¡)
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import torch
import hydra
from omegaconf import DictConfig, OmegaConf
import pytorch_lightning as pl
from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import WandbLogger
from dotenv import load_dotenv

from src.data.datamodule import DocumentImageDataModule
from src.models.module import DocumentClassifierModule
from src.utils.device import get_device


log = logging.getLogger(__name__)


def setup_seed(seed: int):
    """ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ ì„¤ì •"""
    import random
    import numpy as np

    random.seed(seed)
    # NumPy 1.26+ì—ì„œëŠ” np.random.seed ëŒ€ì‹  Generator ì‚¬ìš© ê¶Œì¥í•˜ì§€ë§Œ
    # í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ legacy APIë„ ì„¤ì •
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)


def create_experiment_dir(base_dir: str, model_name: str) -> tuple[Path, str]:
    """ì‹¤í—˜ ë””ë ‰í† ë¦¬ ìƒì„± (ë‚ ì§œ + run_id)

    Args:
        base_dir: ë² ì´ìŠ¤ ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬
        model_name: ëª¨ë¸ ì´ë¦„

    Returns:
        (experiment_dir, run_id): ì‹¤í—˜ ë””ë ‰í† ë¦¬ì™€ run_id
    """
    base_path = Path(base_dir)
    base_path.mkdir(parents=True, exist_ok=True)

    # ë‚ ì§œ ìƒì„± (YYYYMMDD í˜•ì‹)
    date_str = datetime.now().strftime("%Y%m%d")

    # ê°™ì€ ë‚ ì§œì˜ ê¸°ì¡´ ì‹¤í—˜ ì°¾ê¸°
    existing_runs = list(base_path.glob(f"{date_str}_*"))

    if existing_runs:
        # ê°€ì¥ í° run ë²ˆí˜¸ ì°¾ê¸°
        run_numbers = []
        for run_dir in existing_runs:
            try:
                # ì˜ˆ: 20260212_run_003 -> 3
                run_num = int(run_dir.name.split('_')[-1])
                run_numbers.append(run_num)
            except (ValueError, IndexError):
                continue

        next_run = max(run_numbers) + 1 if run_numbers else 1
    else:
        next_run = 1

    # run_id ìƒì„±
    run_id = f"{date_str}_run_{next_run:03d}"

    # ì‹¤í—˜ ë””ë ‰í† ë¦¬ ìƒì„±
    experiment_dir = base_path / run_id
    experiment_dir.mkdir(parents=True, exist_ok=True)

    log.info(f"ì‹¤í—˜ ID: {run_id}")
    log.info(f"ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ê²½ë¡œ: {experiment_dir}")

    return experiment_dir, run_id


def update_champion_model(
    current_checkpoint: Path,
    current_metric: float,
    champion_dir: Path,
    metric_name: str = "val_f1"
) -> bool:
    """ìµœê³  ì„±ëŠ¥ ëª¨ë¸(ì±”í”¼ì–¸) ì—…ë°ì´íŠ¸

    Args:
        current_checkpoint: í˜„ì¬ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ
        current_metric: í˜„ì¬ ë©”íŠ¸ë¦­ ê°’
        champion_dir: ì±”í”¼ì–¸ ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬
        metric_name: ë©”íŠ¸ë¦­ ì´ë¦„

    Returns:
        ìƒˆë¡œìš´ ì±”í”¼ì–¸ ì—¬ë¶€
    """
    champion_dir.mkdir(parents=True, exist_ok=True)
    champion_info_path = champion_dir / "champion_info.json"

    # ê¸°ì¡´ ì±”í”¼ì–¸ ì •ë³´ ë¡œë“œ
    if champion_info_path.exists():
        with open(champion_info_path, 'r') as f:
            champion_info = json.load(f)

        best_metric = champion_info.get(metric_name, 0.0)
    else:
        best_metric = 0.0
        champion_info = {}

    # í˜„ì¬ ëª¨ë¸ì´ ë” ì¢‹ì€ì§€ í™•ì¸
    if current_metric > best_metric:
        # ì±”í”¼ì–¸ ëª¨ë¸ ë³µì‚¬
        champion_checkpoint = champion_dir / "best_model.ckpt"
        shutil.copy2(current_checkpoint, champion_checkpoint)

        # ì±”í”¼ì–¸ ì •ë³´ ì—…ë°ì´íŠ¸
        champion_info.update({
            metric_name: float(current_metric),
            "checkpoint_path": str(current_checkpoint),
            "updated_at": datetime.now().isoformat(),
            "model_name": current_checkpoint.parent.name
        })

        with open(champion_info_path, 'w') as f:
            json.dump(champion_info, f, indent=2)

        log.info("=" * 70)
        log.info("ğŸ† ìƒˆë¡œìš´ ì±”í”¼ì–¸ ëª¨ë¸!")
        log.info(f"   {metric_name}: {best_metric:.4f} â†’ {current_metric:.4f}")
        log.info(f"   ì €ì¥ ê²½ë¡œ: {champion_checkpoint}")
        log.info("=" * 70)

        return True

    return False


@hydra.main(version_base=None, config_path="../configs", config_name="config")
def main(cfg: DictConfig) -> None:
    """ë©”ì¸ í•™ìŠµ í•¨ìˆ˜"""

    # í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (.env íŒŒì¼)
    load_dotenv()

    log.info("ì„¤ì • ì •ë³´:")
    log.info(OmegaConf.to_yaml(cfg))
    
    # ì‹œë“œ ì„¤ì •
    setup_seed(cfg.seed)
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì • (CUDA, MPS, CPU ìë™ ì„ íƒ)
    # Vision Transformer ëª¨ë¸ì€ MPSì—ì„œ í˜¸í™˜ì„± ë¬¸ì œë¡œ ìë™ìœ¼ë¡œ CPUë¡œ fallback
    device, accelerator, devices, device_info = get_device(model_name=cfg.model.model_name)
    log.info(f"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device_info}")
    
    # ë°ì´í„°ëª¨ë“ˆ ìƒì„±
    data_module = DocumentImageDataModule(
        data_root=cfg.data.root_path,
        train_csv=cfg.data.train_csv,
        test_csv=cfg.data.get('test_csv', None),
        train_image_dir=cfg.data.get('train_image_dir', 'train/'),
        test_image_dir=cfg.data.get('test_image_dir', 'test/'),
        img_size=cfg.data.img_size,
        batch_size=cfg.training.batch_size,
        num_workers=cfg.training.num_workers,
        train_val_split=cfg.data.train_val_split,
        normalization=cfg.data.normalization,
        augmentation=cfg.data.augmentation,
        seed=cfg.seed,
        drop_last=cfg.training.get('drop_last', False),
    )
    
    # ë°ì´í„° ì„¤ì • (í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°)
    data_module.setup()
    
    # ëª¨ë¸ ìƒì„±
    model = DocumentClassifierModule(
        model_name=cfg.model.model_name,
        pretrained=cfg.model.pretrained,
        num_classes=cfg.model.num_classes,
        learning_rate=cfg.training.learning_rate,
        weight_decay=cfg.training.weight_decay,
        class_weights=data_module.class_weights,
        warmup_epochs=cfg.training.warmup_epochs,
        epochs=cfg.training.epochs,
    )
    
    log.info(f"ëª¨ë¸: {cfg.model.model_name}")
    log.info(f"ì´ íŒŒë¼ë¯¸í„°: {sum(p.numel() for p in model.parameters()):,}")

    # ì‹¤í—˜ ë””ë ‰í† ë¦¬ ìƒì„± (ë‚ ì§œ + run_id)
    experiment_dir, run_id = create_experiment_dir(
        base_dir=cfg.checkpoint_dir,
        model_name=cfg.model.model_name
    )

    # ì‹¤í—˜ ì •ë³´ ì €ì¥
    experiment_info = {
        "run_id": run_id,
        "model_name": cfg.model.model_name,
        "started_at": datetime.now().isoformat(),
        "config": OmegaConf.to_container(cfg, resolve=True)
    }
    with open(experiment_dir / "experiment_info.json", 'w') as f:
        json.dump(experiment_info, f, indent=2)

    # ì²´í¬í¬ì¸íŠ¸ ì½œë°±
    checkpoint_callback = ModelCheckpoint(
        dirpath=str(experiment_dir),
        filename="{epoch:02d}-{val_f1:.3f}",
        monitor=cfg.training.checkpoint.monitor,
        mode=cfg.training.checkpoint.mode,
        save_top_k=cfg.training.checkpoint.save_top_k,
    )
    
    # ì¡°ê¸° ì¢…ë£Œ ì½œë°±
    early_stopping_callback = EarlyStopping(
        monitor=cfg.training.early_stopping.monitor,
        patience=cfg.training.early_stopping.patience,
        mode=cfg.training.early_stopping.mode,
    )
    
    # WanDB ë¡œê±°
    wandb_logger = WandbLogger(
        project=cfg.wandb.project,
        entity=cfg.wandb.entity,
        name=f"{cfg.model.model_name}-{run_id}",
        log_model=cfg.wandb.log_model,
        mode=cfg.wandb.mode,
    )

    # WanDBì— ì „ì²´ ì„¤ì • ì €ì¥
    wandb_logger.experiment.config.update(OmegaConf.to_container(cfg))

    # Mixed Precision ì„¤ì •
    precision = '16-mixed' if cfg.training.get('use_amp', False) else 32
    if precision == '16-mixed':
        log.info("âœ¨ Mixed Precision (AMP) í™œì„±í™”")

    # íŠ¸ë ˆì´ë„ˆ ì„¤ì •
    trainer = pl.Trainer(
        max_epochs=cfg.training.epochs,
        accelerator=accelerator,
        devices=devices,
        logger=wandb_logger,
        callbacks=[checkpoint_callback, early_stopping_callback],
        log_every_n_steps=cfg.training.log_interval,
        val_check_interval=cfg.training.val_check_interval,
        enable_progress_bar=True,
        precision=precision,
    )
    
    # í•™ìŠµ
    log.info("í•™ìŠµ ì‹œì‘...")
    trainer.fit(model, datamodule=data_module)

    # í…ŒìŠ¤íŠ¸ (test.csvëŠ” ë ˆì´ë¸”ì´ ë”ë¯¸ ë°ì´í„°ì´ë¯€ë¡œ ì œê±°)
    # ë¦¬ë”ë³´ë“œ ì œì¶œìš© ì¶”ë¡ ì€ inference.py ì‚¬ìš©
    # log.info("í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    # trainer.test(model, datamodule=data_module)

    # ìµœê³  ì„±ëŠ¥ ì²´í¬í¬ì¸íŠ¸ ì°¾ê¸° ë° ì±”í”¼ì–¸ ëª¨ë¸ ì—…ë°ì´íŠ¸
    best_checkpoint = checkpoint_callback.best_model_path
    if best_checkpoint and os.path.exists(best_checkpoint):
        # PyTorch Lightningì˜ best_model_score ì‚¬ìš© (íŒŒì¼ëª… íŒŒì‹± ë¶ˆí•„ìš”)
        try:
            val_f1 = checkpoint_callback.best_model_score.item()

            # ì±”í”¼ì–¸ ë””ë ‰í† ë¦¬
            champion_dir = Path(cfg.checkpoint_dir) / "champion"

            # ì±”í”¼ì–¸ ëª¨ë¸ ì—…ë°ì´íŠ¸
            is_new_champion = update_champion_model(
                current_checkpoint=Path(best_checkpoint),
                current_metric=val_f1,
                champion_dir=champion_dir,
                metric_name="val_f1"
            )

            # ì‹¤í—˜ ì •ë³´ ì—…ë°ì´íŠ¸
            experiment_info["best_checkpoint"] = str(best_checkpoint)
            experiment_info["val_f1"] = val_f1
            experiment_info["is_champion"] = is_new_champion
            experiment_info["completed_at"] = datetime.now().isoformat()

            with open(experiment_dir / "experiment_info.json", 'w') as f:
                json.dump(experiment_info, f, indent=2)

        except Exception as e:
            log.warning(f"ì±”í”¼ì–¸ ëª¨ë¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

    log.info("í•™ìŠµ ì™„ë£Œ!")
    log.info(f"ì‹¤í—˜ ID: {run_id}")
    log.info(f"ì²´í¬í¬ì¸íŠ¸: {experiment_dir}")
    log.info("ğŸ’¡ Inferenceë¥¼ ìˆ˜í–‰í•˜ë ¤ë©´: python src/inference.py")


if __name__ == "__main__":
    main()
