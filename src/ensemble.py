"""
Ensemble ì‹œìŠ¤í…œ
- Voting (Hard/Soft)
- Weighted Averaging
- Stacking
"""

import os
import json
import logging
from pathlib import Path
from typing import List, Optional, Dict

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€ (ì–´ë””ì„œë“  ì‹¤í–‰ ê°€ëŠ¥í•˜ë„ë¡)
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import torch
import pandas as pd
import numpy as np
from tqdm import tqdm
import hydra
from omegaconf import DictConfig
from scipy import stats

from src.data.datamodule import DocumentImageDataModule
from src.models.module import DocumentClassifierModule
from src.utils.device import get_simple_device

log = logging.getLogger(__name__)


def load_models(checkpoint_paths: List[str]) -> List[DocumentClassifierModule]:
    """ì—¬ëŸ¬ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ"""
    models = []
    for ckpt_path in checkpoint_paths:
        if not os.path.exists(ckpt_path):
            log.warning(f"ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {ckpt_path}")
            continue

        log.info(f"ë¡œë“œ ì¤‘: {ckpt_path}")
        model = DocumentClassifierModule.load_from_checkpoint(ckpt_path)
        model.eval()
        models.append(model)

    return models


def predict_single_model(
    model: DocumentClassifierModule,
    data_loader,
    device: torch.device,
    return_probs: bool = True
) -> np.ndarray:
    """ë‹¨ì¼ ëª¨ë¸ë¡œ ì˜ˆì¸¡"""
    all_outputs = []

    with torch.no_grad():
        for batch in data_loader:
            images, _ = batch
            images = images.to(device)

            logits = model(images)

            if return_probs:
                probs = torch.softmax(logits, dim=1)
                all_outputs.append(probs.cpu().numpy())
            else:
                preds = logits.argmax(dim=1)
                all_outputs.append(preds.cpu().numpy())

    return np.concatenate(all_outputs, axis=0)


def hard_voting(predictions: List[np.ndarray]) -> np.ndarray:
    """Hard Voting: ë‹¤ìˆ˜ê²°"""
    # predictions: List[N,] -> (num_models, N)
    votes = np.stack(predictions, axis=0)
    # ê° ìƒ˜í”Œì— ëŒ€í•´ ìµœë¹ˆê°’
    final_preds, _ = stats.mode(votes, axis=0, keepdims=False)
    return final_preds


def soft_voting(probabilities: List[np.ndarray], weights: Optional[List[float]] = None) -> tuple[np.ndarray, np.ndarray]:
    """Soft Voting: í™•ë¥  í‰ê· """
    # probabilities: List[N, C] -> (num_models, N, C)
    probs = np.stack(probabilities, axis=0)

    if weights is None:
        # ê· ë“± ê°€ì¤‘ì¹˜
        avg_probs = np.mean(probs, axis=0)
    else:
        # ê°€ì¤‘ í‰ê· 
        weights = np.array(weights).reshape(-1, 1, 1)  # (num_models, 1, 1)
        avg_probs = np.sum(probs * weights, axis=0) / np.sum(weights)

    # ìµœì¢… ì˜ˆì¸¡
    final_preds = np.argmax(avg_probs, axis=1)
    return final_preds, avg_probs


def rank_averaging(probabilities: List[np.ndarray]) -> np.ndarray:
    """Rank Averaging: ìˆœìœ„ ê¸°ë°˜ ì•™ìƒë¸”"""
    # ê° ëª¨ë¸ì˜ í™•ë¥ ì„ rankë¡œ ë³€í™˜
    ranks = []
    for probs in probabilities:
        # ê° ìƒ˜í”Œì— ëŒ€í•´ í´ë˜ìŠ¤ë³„ ìˆœìœ„
        rank = np.argsort(np.argsort(-probs, axis=1), axis=1)  # ë‚®ì€ rank = ë†’ì€ í™•ë¥ 
        ranks.append(rank)

    # í‰ê·  rank
    avg_rank = np.mean(np.stack(ranks, axis=0), axis=0)

    # rankê°€ ê°€ì¥ ë‚®ì€ í´ë˜ìŠ¤ ì„ íƒ
    final_preds = np.argmin(avg_rank, axis=1)
    return final_preds


@hydra.main(version_base=None, config_path="../configs", config_name="config")
def main(cfg: DictConfig) -> None:
    """ë©”ì¸ ensemble í•¨ìˆ˜

    Hydra configë¡œ ì•™ìƒë¸” ì„¤ì • ê´€ë¦¬:
        ensemble.checkpoints: ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        ensemble.method: "hard_voting" | "soft_voting" | "rank_averaging"
        ensemble.weights: ëª¨ë¸ ê°€ì¤‘ì¹˜ (ì„ íƒì‚¬í•­)
        ensemble.output: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
    """
    # Hydra configì—ì„œ ì•™ìƒë¸” ì„¤ì • ì½ê¸°
    ensemble_cfg = cfg.get('ensemble', {})
    checkpoints = ensemble_cfg.get('checkpoints', [])
    method = ensemble_cfg.get('method', 'soft_voting')
    weights = ensemble_cfg.get('weights', None)
    output = ensemble_cfg.get('output', 'pred_ensemble.csv')

    if not checkpoints:
        raise ValueError(
            "ensemble.checkpointsê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
            "configs/ensemble.yamlì„ ìƒì„±í•˜ê±°ë‚˜ CLIë¡œ ì „ë‹¬í•˜ì„¸ìš”: "
            "python src/ensemble.py ensemble.checkpoints=[path1,path2]"
        )

    log.info("=" * 70)
    log.info("ğŸ”® Ensemble Inference ì‹œì‘")
    log.info("=" * 70)
    log.info(f"ë°©ë²•: {method}")
    log.info(f"ëª¨ë¸ ìˆ˜: {len(checkpoints)}")

    # ëª¨ë¸ ë¡œë“œ
    models = load_models(checkpoints)

    if len(models) == 0:
        raise ValueError("ë¡œë“œëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")

    if len(models) == 1:
        log.warning("ëª¨ë¸ì´ 1ê°œë§Œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤. ì•™ìƒë¸” íš¨ê³¼ ì—†ìŒ.")

    # ë°ì´í„° ë¡œë“œ
    test_csv_path = os.path.join(cfg.data.root_path, cfg.data.test_csv)
    if not os.path.exists(test_csv_path):
        raise FileNotFoundError(f"í…ŒìŠ¤íŠ¸ CSVë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {test_csv_path}")

    data_module = DocumentImageDataModule(
        data_root=cfg.data.root_path,
        train_csv=cfg.data.train_csv,
        test_csv=cfg.data.test_csv,
        train_image_dir=cfg.data.get('train_image_dir', 'train/'),
        test_image_dir=cfg.data.get('test_image_dir', 'test/'),
        img_size=cfg.data.img_size,
        batch_size=cfg.training.batch_size,
        num_workers=cfg.training.num_workers,
        train_val_split=cfg.data.train_val_split,
        normalization=cfg.data.normalization,
        augmentation=cfg.data.augmentation,
    )
    data_module.setup()
    test_loader = data_module.test_dataloader()

    # ë””ë°”ì´ìŠ¤ ì„¤ì • (CUDA -> MPS -> CPU ìë™ ê°ì§€)
    device = get_simple_device()
    log.info(f"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")

    # ê° ëª¨ë¸ë¡œ ì˜ˆì¸¡
    log.info("\nğŸ“Š ëª¨ë¸ë³„ ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘...")
    all_predictions = []
    all_probabilities = []

    for i, model in enumerate(models):
        model = model.to(device)
        log.info(f"\nëª¨ë¸ {i+1}/{len(models)} ì˜ˆì¸¡ ì¤‘...")

        if method == "hard_voting":
            preds = predict_single_model(model, test_loader, device, return_probs=False)
            all_predictions.append(preds)
        else:
            probs = predict_single_model(model, test_loader, device, return_probs=True)
            all_probabilities.append(probs)

    # ì•™ìƒë¸”
    log.info(f"\nğŸ”„ {method} ì ìš© ì¤‘...")

    if method == "hard_voting":
        final_preds = hard_voting(all_predictions)
        final_probs = None

    elif method == "soft_voting":
        final_preds, final_probs = soft_voting(all_probabilities, weights)

    elif method == "rank_averaging":
        final_preds = rank_averaging(all_probabilities)
        final_probs = None

    log.info(f"ì´ ì˜ˆì¸¡ ìˆ˜: {len(final_preds)}")

    # ê²°ê³¼ ì €ì¥
    sample_submission_path = os.path.join(cfg.data.root_path, "sample_submission.csv")

    if os.path.exists(sample_submission_path):
        sample_df = pd.read_csv(sample_submission_path)
        sample_df.iloc[:, 1] = final_preds[:len(sample_df)]
        result_df = sample_df
    else:
        test_df = pd.read_csv(test_csv_path)
        image_ids = test_df.iloc[:, 0].tolist()
        result_df = pd.DataFrame({
            'id': image_ids[:len(final_preds)],
            'target': final_preds
        })

    result_df.to_csv(output, index=False)

    log.info("=" * 70)
    log.info(f"âœ… Ensemble ì™„ë£Œ!")
    log.info(f"ğŸ“„ ê²°ê³¼ ì €ì¥: {output}")
    log.info("=" * 70)

    # í†µê³„
    pred_counts = pd.Series(final_preds).value_counts().sort_index()
    log.info("\nğŸ“ˆ ì˜ˆì¸¡ í´ë˜ìŠ¤ ë¶„í¬:")
    for class_id, count in pred_counts.items():
        log.info(f"  í´ë˜ìŠ¤ {class_id}: {count:4d} ({count/len(final_preds)*100:5.2f}%)")

    # ì•™ìƒë¸” ì •ë³´ ì €ì¥
    ensemble_info = {
        "method": method,
        "num_models": len(models),
        "checkpoints": checkpoints,
        "weights": weights,
        "output": output
    }

    info_path = output.replace(".csv", "_info.json")
    with open(info_path, 'w') as f:
        json.dump(ensemble_info, f, indent=2)

    log.info(f"\nğŸ’¾ ì•™ìƒë¸” ì •ë³´ ì €ì¥: {info_path}")


if __name__ == "__main__":
    main()
