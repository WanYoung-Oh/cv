# CV í”„ë¡œì íŠ¸ ì™„ë£Œ ê°€ì´ë“œ

> PyTorch Lightning + Hydra + WanDB ê¸°ë°˜ ë¬¸ì„œ ì´ë¯¸ì§€ ë¶„ë¥˜ ì‹œìŠ¤í…œ

**í”„ë¡œì íŠ¸ ìƒíƒœ**: âœ… ì™„ë£Œ (F1 0.993 ë‹¬ì„±)
**ëª©í‘œ ë‹¬ì„±**: 113% (ëª©í‘œ 0.88 vs ì‹¤ì œ 0.993)
**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2026-02-17

---

## ğŸ‰ ë‹¬ì„± ì„±ê³¼

| Metric | ëª©í‘œ | ë‹¬ì„± | ìƒíƒœ |
|--------|------|------|------|
| **F1-Macro** | 0.88+ | **0.993** | âœ… +13% ì´ˆê³¼ |
| **Accuracy** | - | **0.994** | âœ… ìš°ìˆ˜ |
| **Val F1** | - | **0.993** | âœ… ì•ˆì •ì  |
| **Test F1** | - | **0.993** | âœ… ì¼ì¹˜ |

**Best ëª¨ë¸**: ResNet34 + baseline_aug (768Ã—768)
**ì²´í¬í¬ì¸íŠ¸**: `checkpoints/champion/best_model.ckpt`

---

## ğŸ“Š ë°ì´í„°ì…‹ ì •ë³´

### êµ¬ì¡°
```
datasets_fin/
â”œâ”€â”€ train.csv               (1,570ê°œ, ë ˆì´ë¸” ìˆìŒ)
â”œâ”€â”€ sample_submission.csv   (3,140ê°œ, ë¦¬ë”ë³´ë“œ ì œì¶œ í˜•ì‹)
â”œâ”€â”€ meta.csv                (17ê°œ í´ë˜ìŠ¤)
â”œâ”€â”€ train/                  (í›ˆë ¨ ì´ë¯¸ì§€)
â”œâ”€â”€ test/                   (í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€, ë¦¬ë”ë³´ë“œ ì œì¶œìš©)
â””â”€â”€ submission/             (inference ê²°ê³¼ ìë™ ì €ì¥)
```

### í´ë˜ìŠ¤ ì •ë³´
- **ì´ 17ê°œ í´ë˜ìŠ¤**: ë¬¸ì„œ íƒ€ì… (ì´ë ¥ì„œ, ì—¬ê¶Œ, ìš´ì „ë©´í—ˆì¦ ë“±)
- **ë¶ˆê· í˜•**: ìƒìœ„ 3ê°œ í´ë˜ìŠ¤ê°€ ì „ì²´ì˜ 50%
- **í•´ê²°**: Class Weights ì ìš©

### ì´ë¯¸ì§€ íŠ¹ì„±
- **í‰ê·  í¬ê¸°**: 498Ã—538 (AR: 0.97)
- **í¬ê¸° ë²”ìœ„**: W: 384~753, H: 348~682
- **ë°©í–¥ì„±**: ì„¸ë¡œ 1,040ê°œ, ê°€ë¡œ 513ê°œ, ì •ì‚¬ê° 17ê°œ

---

## ğŸ¤– ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸

### CNN ëª¨ë¸ (768Ã—768)
| ëª¨ë¸ | Config | Data Config | ì˜ˆìƒ ì„±ëŠ¥ | ë¹„ê³  |
|------|--------|-------------|-----------|------|
| **ResNet34** âœ… | resnet34 | baseline_aug | **F1 0.993** | Best ëª¨ë¸ |
| ResNet50 | resnet50 | baseline_aug | F1 0.96~0.98 | ì•ˆì •ì  |
| EfficientNet-B4 | efficientnet_b4 | baseline_aug | F1 0.96~0.98 | íš¨ìœ¨ì , batch_size=8 |
| ConvNeXt-Base | convnext_base | baseline_aug | F1 0.96~0.98 | ìµœì‹  CNN |

### Transformer ëª¨ë¸ (384Ã—384)
| ëª¨ë¸ | Config | Data Config | ì˜ˆìƒ ì„±ëŠ¥ | ë¹„ê³  |
|------|--------|-------------|-----------|------|
| Swin-Base-384 | swin_base_384 | transformer_384 | F1 0.95~0.97 | Window 12 |
| DeiT-Base-384 | deit_base_384 | transformer_384 | F1 0.94~0.96 | ViT ê°œì„  |

---

## ğŸš€ ì‚¬ìš© ë°©ë²•

### 1. í™˜ê²½ ì„¤ì •
```bash
conda activate pytorch_test
pip install -r requirements.txt
```

### 2. í›ˆë ¨

#### Best ëª¨ë¸ ì¬í˜„ (ResNet34)
```bash
python src/train.py \
  data=baseline_aug \
  model=resnet34 \
  training=baseline_768
```

#### Transformer ëª¨ë¸ ì‹¤í—˜
```bash
# Swin-Base-384
python src/train.py \
  data=transformer_384 \
  model=swin_base_384 \
  training=baseline_768

# DeiT-Base-384
python src/train.py \
  data=transformer_384 \
  model=deit_base_384 \
  training=baseline_768
```

#### CNN ëª¨ë¸ ì‹¤í—˜
```bash
# EfficientNet-B4 (ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ)
python src/train.py \
  data=baseline_aug \
  model=efficientnet_b4 \
  training=baseline_768 \
  training.batch_size=8

# ConvNeXt-Base
python src/train.py \
  data=baseline_aug \
  model=convnext_base \
  training=baseline_768
```

### 3. Inference (ë¦¬ë”ë³´ë“œ ì œì¶œ)
```bash
# Champion ëª¨ë¸ ì‚¬ìš© (ê¸°ë³¸)
python src/inference.py
# ì¶œë ¥: datasets_fin/submission/submission_{model_name}.csv

# íŠ¹ì • run_id ì‚¬ìš©
python src/inference.py inference.run_id=20260216_run_001

# ì§ì ‘ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ì§€ì •
python src/inference.py inference.checkpoint=checkpoints/20260215_run_002/epoch=10-val_f1=0.993.ckpt

# ì¶œë ¥ íŒŒì¼ëª… ì§ì ‘ ì§€ì •
python src/inference.py inference.output=datasets_fin/submission/submission_final.csv
```

### 4. ê²°ê³¼ ë¶„ì„
```bash
# Confusion Matrix ìƒì„±
python scripts/analyze_results.py --checkpoint checkpoints/champion/best_model.ckpt

# ì¶œë ¥: analysis_results/confusion_matrix.png
```

---

## âš™ï¸ Config êµ¬ì¡°

### Model Configs (configs/model/)
```yaml
# CNN (768Ã—768ìš©)
- resnet34.yaml           # Best ëª¨ë¸ â­
- resnet50.yaml
- efficientnet_b4.yaml
- convnext_base.yaml

# Transformer (384Ã—384ìš©)
- swin_base_384.yaml
- deit_base_384.yaml
```

### Data Configs (configs/data/)
```yaml
# CNNìš© (768Ã—768)
baseline_aug.yaml:
  - LongestMaxSize(768) + PadIfNeeded(768Ã—768)
  - RandomRotate90, Rotate Â±45Â°
  - CLAHE, Perspective, ColorJitter ë“±

# Transformerìš© (384Ã—384)
transformer_384.yaml:
  - LongestMaxSize(384) + PadIfNeeded(384Ã—384)
  - ë™ì¼í•œ Augmentation
```

### Training Configs (configs/training/)
```yaml
baseline_768.yaml:
  - batch_size: 16
  - learning_rate: 1e-3
  - epochs: 50
  - early_stopping: patience=10
```

---

## ğŸ¯ í•µì‹¬ ì„±ê³µ ìš”ì¸

### 1. ê³ í•´ìƒë„ ì…ë ¥ (768Ã—768)
- ê¸°ì¡´ 224Ã—224 ëŒ€ë¹„ **3.4ë°°** í•´ìƒë„
- ë¬¸ì„œì˜ ì„¸ë¶€ ì •ë³´ ì™„ë²½ ë³´ì¡´
- í…ìŠ¤íŠ¸ ì¸ì‹ ì„±ëŠ¥ í–¥ìƒ

### 2. Aspect Ratio ë³´ì¡´
- **LongestMaxSize + PadIfNeeded** 2ë‹¨ê³„ ì „ëµ
- ì •ë³´ ì†ì‹¤ ìµœì†Œí™”
- ì™œê³¡ ë°©ì§€

### 3. ë¬¸ì„œ íŠ¹í™” Augmentation
- **CLAHE**: ëŒ€ë¹„ ê°•í™” (ì‰í¬/ì¢…ì´ ë¶„ë¦¬)
- **Perspective**: ìŠ¤ìº” ê°ë„ ë³€í™”
- **ColorJitter**: ì¢…ì´ ìƒ‰ìƒ ë³€í™”
- **Sharpen**: ì„ ëª…ë„ í–¥ìƒ

### 4. Class Weights
- ë¶ˆê· í˜• ë°ì´í„° ì²˜ë¦¬ ì„±ê³µ
- Weight ë²”ìœ„: 1.00 ~ 2.17
- Weighted CrossEntropy Loss ì‚¬ìš©

---

## ğŸ“ˆ ë‹¤ìŒ ë‹¨ê³„ (ì„ íƒì‚¬í•­)

### ì˜µì…˜ A: í˜„ì¬ ê²°ê³¼ë¡œ ì™„ë£Œ (ì¶”ì²œ) â­
- **í˜„ì¬ ì„±ëŠ¥**: F1 0.993 (ëª©í‘œ ëŒ€ë¹„ +13%)
- **ìƒíƒœ**: í”„ë¡œì íŠ¸ ëª©í‘œ ì´ˆê³¼ ë‹¬ì„±
- **ë‹¤ìŒ**: ë¦¬ë”ë³´ë“œ ì œì¶œ, í”„ë¡œì íŠ¸ ì™„ë£Œ

### ì˜µì…˜ B: TTA + Ensemble
- **ëª©í‘œ**: F1 0.995+ ë„ì „
- **ë°©ë²•**:
  1. TTA: 4ê°€ì§€ íšŒì „ (0Â°, 90Â°, 180Â°, 270Â°)
  2. Ensemble: ResNet34 + Swin-384 + DeiT-384
- **ì˜ˆìƒ ì‹œê°„**: 3~4ì‹œê°„
- **ROI**: ë‚®ìŒ (+0.2~0.4%)

### ì˜µì…˜ C: Transformer ëª¨ë¸ ì‹¤í—˜
- **ëª©í‘œ**: ë‹¤ì–‘í•œ ì•„í‚¤í…ì²˜ ê²½í—˜
- **ë°©ë²•**: Swin-384, DeiT-384 í›ˆë ¨
- **ì˜ˆìƒ ì‹œê°„**: ê° 2~3ì‹œê°„
- **ROI**: ë§¤ìš° ë‚®ìŒ

---

## ğŸ“š ì°¸ê³  ìë£Œ

### PDCA ë¬¸ì„œ
- [data-augmentation-strategy.md](02-design/data-augmentation-strategy.md) - ì„¤ê³„ ë¬¸ì„œ
- [CV.analysis.md](03-analysis/CV.analysis.md) - Gap Analysis (Match Rate 95%)
- [CV.report.md](04-report/CV.report.md) - ì™„ë£Œ ë³´ê³ ì„œ

### Config íŒŒì¼
- [baseline_aug.yaml](../configs/data/baseline_aug.yaml) - Best ì„±ëŠ¥ config
- [transformer_384.yaml](../configs/data/transformer_384.yaml) - Transformerìš©
- [baseline_768.yaml](../configs/training/baseline_768.yaml) - í›ˆë ¨ ì„¤ì •

### ì½”ë“œ
- [train.py](../src/train.py) - í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸
- [inference.py](../src/inference.py) - ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸
- [analyze_results.py](../scripts/analyze_results.py) - ê²°ê³¼ ë¶„ì„

---

## ğŸ”§ ë¬¸ì œ í•´ê²°

### ë©”ëª¨ë¦¬ ë¶€ì¡±
```bash
# Batch size ê°ì†Œ
python src/train.py training.batch_size=8

# ì‘ì€ ëª¨ë¸ ì‚¬ìš©
python src/train.py model=resnet34  # 21M params
```

### WanDB ë¡œê·¸ì¸
```bash
wandb login

# ë˜ëŠ” .env íŒŒì¼ ì„¤ì •
WANDB_API_KEY=your-api-key
WANDB_PROJECT=doc_image_classification
```

### Config ì˜¤ë²„ë¼ì´ë“œ
```bash
# CLIì—ì„œ ëª¨ë“  í•˜ì´í¼íŒŒë¼ë¯¸í„° ë³€ê²½ ê°€ëŠ¥
python src/train.py \
  training.learning_rate=5e-4 \
  training.epochs=30 \
  training.batch_size=8
```

---

## ğŸ“ ì£¼ìš” ëª…ë ¹ì–´ ìš”ì•½

```bash
# í›ˆë ¨ (Best ëª¨ë¸)
python src/train.py data=baseline_aug model=resnet34 training=baseline_768

# Inference
python src/inference.py checkpoint=checkpoints/champion/best_model.ckpt

# ê²°ê³¼ ë¶„ì„
python scripts/analyze_results.py --checkpoint checkpoints/champion/best_model.ckpt

# WanDB ëŒ€ì‹œë³´ë“œ
# í›ˆë ¨ ì‹œì‘ í›„ í„°ë¯¸ë„ì˜ URL í´ë¦­
```

---

## ğŸ’¡ í•™ìŠµ ë‚´ìš©

### ì„±ê³µ ìš”ì¸
1. ê³ í•´ìƒë„ ì…ë ¥ì´ ë¬¸ì„œ ì´ë¯¸ì§€ì— í•„ìˆ˜
2. Aspect ratio ë³´ì¡´ì´ ì •ë³´ ì†ì‹¤ ìµœì†Œí™”
3. ë„ë©”ì¸ íŠ¹í™” augmentationì´ ì¼ë°˜ augmentationë³´ë‹¤ íš¨ê³¼ì 
4. Baselineë¶€í„° ì‹œì‘í•˜ì—¬ ë‹¨ê³„ì  ê°œì„ ì´ íš¨ìœ¨ì 

### ì˜ˆìƒê³¼ ë‹¤ë¥¸ ì 
- **ì„¤ê³„ ì˜ˆìƒ**: F1 0.82~0.85
- **ì‹¤ì œ ë‹¬ì„±**: F1 0.993
- **ì°¨ì´ ì´ìœ **: ê³ í•´ìƒë„ + ë¬¸ì„œ íŠ¹í™” augmentationì˜ ì‹œë„ˆì§€

### ë‹¤ìŒ í”„ë¡œì íŠ¸ë¥¼ ìœ„í•œ êµí›ˆ
1. ë¬¸ì„œ ì´ë¯¸ì§€ëŠ” ê³ í•´ìƒë„ (768+) í•„ìˆ˜
2. Aspect ratio ë³´ì¡´ ìš°ì„ 
3. ë„ë©”ì¸ ì§€ì‹ í™œìš©í•œ augmentation ì„¤ê³„
4. ResNet ê°™ì€ ê²€ì¦ëœ ì•„í‚¤í…ì²˜ì˜ ê°•ë ¥í•¨

---

**í”„ë¡œì íŠ¸ ì™„ë£Œì¼**: 2026-02-15
**ìµœì¢… ì„±ê³¼**: F1 0.993 (ëª©í‘œ 0.88 ëŒ€ë¹„ +13%)
**Best ëª¨ë¸**: ResNet34 + baseline_aug (768Ã—768)
